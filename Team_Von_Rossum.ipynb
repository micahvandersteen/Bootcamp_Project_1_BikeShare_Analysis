{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from pprint import pprint\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "\n",
    "# import census\n",
    "from census import Census\n",
    "from us import states\n",
    "# Census API Key\n",
    "from config import api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carl's code\n",
    "\n",
    "# Read in the individual bike files, append a new column for month\n",
    "m_df1 = pd.read_csv(\"resources/Minneapolis/201804-niceride-tripdata.csv\")\n",
    "m_df1[\"Month\"] = \"April\"\n",
    "m_df2 = pd.read_csv(\"resources/Minneapolis/201805-niceride-tripdata.csv\")\n",
    "m_df2[\"Month\"] = \"May\"\n",
    "m_df3 = pd.read_csv(\"resources/Minneapolis/201806-niceride-tripdata.csv\")\n",
    "m_df3[\"Month\"] = \"June\"\n",
    "m_df4 = pd.read_csv(\"resources/Minneapolis/201807-niceride-tripdata.csv\")\n",
    "m_df4[\"Month\"] = \"July\"\n",
    "m_df5 = pd.read_csv(\"resources/Minneapolis/201808-niceride-tripdata.csv\")\n",
    "m_df5[\"Month\"] = \"August\"\n",
    "m_df6 = pd.read_csv(\"resources/Minneapolis/201809-niceride-tripdata.csv\")\n",
    "m_df6[\"Month\"] = \"September\"\n",
    "m_df7 = pd.read_csv(\"resources/Minneapolis/201810-niceride-tripdata.csv\")\n",
    "m_df7[\"Month\"] = \"October\"\n",
    "m_df8 = pd.read_csv(\"resources/Minneapolis/201811-niceride-tripdata.csv\")\n",
    "m_df8[\"Month\"] = \"November\"\n",
    "\n",
    "# create a new data frame and append individual data frames together\n",
    "m_df = pd.DataFrame()\n",
    "m_df = m_df1.append(m_df2).append(m_df3).append(m_df4).append(m_df5).append(m_df6).append(m_df7).append(m_df8)\n",
    "m_df.to_csv('census_output/m_bike.csv')\n",
    "# m_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the individual bike files, append a new column for month\n",
    "b_df1 = pd.read_csv(\"resources/Boston/201801_hubway_tripdata.csv\")\n",
    "b_df1[\"Month\"] = \"January\"\n",
    "b_df2 = pd.read_csv(\"resources/Boston/201802_hubway_tripdata.csv\")\n",
    "b_df2[\"Month\"] = \"February\"\n",
    "b_df3 = pd.read_csv(\"resources/Boston/201803_hubway_tripdata.csv\")\n",
    "b_df3[\"Month\"] = \"March\"\n",
    "b_df4 = pd.read_csv(\"resources/Boston/201804-hubway-tripdata.csv\")\n",
    "b_df4[\"Month\"] = \"April\"\n",
    "b_df5 = pd.read_csv(\"resources/Boston/201805-bluebikes-tripdata.csv\")\n",
    "b_df5[\"Month\"] = \"May\"\n",
    "b_df6 = pd.read_csv(\"resources/Boston/201806-bluebikes-tripdata.csv\")\n",
    "b_df6[\"Month\"] = \"June\"\n",
    "b_df7 = pd.read_csv(\"resources/Boston/201807-bluebikes-tripdata.csv\")\n",
    "b_df7[\"Month\"] = \"July\"\n",
    "b_df8 = pd.read_csv(\"resources/Boston/201808-bluebikes-tripdata.csv\")\n",
    "b_df8[\"Month\"] = \"August\"\n",
    "b_df9 = pd.read_csv(\"resources/Boston/201809-bluebikes-tripdata.csv\")\n",
    "b_df9[\"Month\"] = \"September\"\n",
    "b_df10 = pd.read_csv(\"resources/Boston/201810-bluebikes-tripdata.csv\")\n",
    "b_df10[\"Month\"] = \"October\"\n",
    "b_df11 = pd.read_csv(\"resources/Boston/201811-bluebikes-tripdata.csv\")\n",
    "b_df11[\"Month\"] = \"November\"\n",
    "b_df12 = pd.read_csv(\"resources/Boston/201812-bluebikes-tripdata.csv\")\n",
    "b_df12[\"Month\"] = \"December\"\n",
    "\n",
    "# create a new data frame and append individual data frames together\n",
    "b_df = pd.DataFrame()\n",
    "b_df = b_df1.append(b_df2).append(b_df3).append(b_df4).append(b_df5).append(b_df6).append(b_df7).append(b_df8).append(b_df9).append(b_df10).append(b_df11).append(b_df12)\n",
    "b_df.to_csv('census_output/b_bike.csv')\n",
    "b_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_df1 = pd.read_csv(\"resources/Portland/2018_01.csv\")\n",
    "p_df1[\"Month\"] = \"January\"\n",
    "p_df2 = pd.read_csv(\"resources/Portland/2018_02.csv\")\n",
    "p_df2[\"Month\"] = \"February\"\n",
    "p_df3 = pd.read_csv(\"resources/Portland/2018_03.csv\")\n",
    "p_df3[\"Month\"] = \"March\"\n",
    "p_df4 = pd.read_csv(\"resources/Portland/2018_04.csv\")\n",
    "p_df4[\"Month\"] = \"April\"\n",
    "p_df5 = pd.read_csv(\"resources/Portland/2018_05.csv\")\n",
    "p_df5[\"Month\"] = \"May\"\n",
    "p_df6 = pd.read_csv(\"resources/Portland/2018_06.csv\")\n",
    "p_df6[\"Month\"] = \"June\"\n",
    "p_df7 = pd.read_csv(\"resources/Portland/2018_07.csv\")\n",
    "p_df7[\"Month\"] = \"July\"\n",
    "p_df8 = pd.read_csv(\"resources/Portland/2018_08.csv\")\n",
    "p_df8[\"Month\"] = \"August\"\n",
    "p_df9 = pd.read_csv(\"resources/Portland/2018_09.csv\")\n",
    "p_df9[\"Month\"] = \"September\"\n",
    "p_df10 = pd.read_csv(\"resources/Portland/2018_10.csv\")\n",
    "p_df10[\"Month\"] = \"October\"\n",
    "p_df11 = pd.read_csv(\"resources/Portland/2018_11.csv\")\n",
    "p_df11[\"Month\"] = \"November\"\n",
    "p_df12 = pd.read_csv(\"resources/Portland/2018_12.csv\")\n",
    "p_df12[\"Month\"] = \"December\"\n",
    "\n",
    "# create a new data frame and append individual data frames together\n",
    "p_df = pd.DataFrame()\n",
    "p_df = p_df1.append(p_df2).append(p_df3).append(p_df4).append(p_df5).append(p_df6).append(p_df7).append(p_df8).append(p_df9).append(p_df10).append(p_df11).append(p_df12)\n",
    "p_df.to_csv('census_output/p_bike.csv')\n",
    "p_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Start bringing in census data. We want the data per census tract of the counties that contain Minneapolis, Boston and Portland\n",
    "\n",
    "# Get census data for Minneapolis\n",
    "c = Census(api_key, year=2017)\n",
    "m_census_data = c.acs5.get(('NAME','B01003_001E', 'B19013_001E', 'B17001_002E', 'B08301_001E', 'B08301_003E', 'B08101_041E',), geo={'for': 'tract:*',\n",
    "                       'in': 'state:{} county:053'.format(states.MN.fips)}) #  county:053 is Hennepin County\n",
    "# Convert to DataFrame\n",
    "m_census_pd = pd.DataFrame(m_census_data)\n",
    "\n",
    "# Column Renaming\n",
    "m_census_pd = m_census_pd.rename(columns={\"B01003_001E\": \"Population\",\n",
    "                                      \"B19013_001E\": \"Median Household Income\",\n",
    "                                      \"B17001_002E\": \"Poverty count\",\n",
    "                                      \"B08301_001E\": \"Commuting count\",\n",
    "                                      \"B08301_003E\": \"Commuting by car count\",\n",
    "                                      \"B08101_041E\": \"Commuting OTHER count\",\n",
    "                                      \"NAME\": \"Name\", \"tract\": \"Census Tract\"})\n",
    "\n",
    "# Add in Poverty Rate (Poverty Count / Population)\n",
    "m_census_pd[\"Poverty Rate\"] = 100 * \\\n",
    "    m_census_pd[\"Poverty count\"].astype(\n",
    "        int) / m_census_pd[\"Population\"].astype(int)\n",
    "\n",
    "# Calculate commute by car\n",
    "m_census_pd[\"Car Rate\"] = 100 * \\\n",
    "    m_census_pd[\"Commuting by car count\"].astype(\n",
    "        int) / m_census_pd[\"Commuting count\"].astype(int)\n",
    "\n",
    "# Calculate commute by OTHER\n",
    "m_census_pd[\"Commute OTHER rate\"] = 100 * \\\n",
    "    m_census_pd[\"Commuting OTHER count\"].astype(\n",
    "        int) / m_census_pd[\"Commuting count\"].astype(int)\n",
    "\n",
    "# Calculate GEOID <= this is used to join to census geography\n",
    "m_census_pd[\"GEOID\"] = m_census_pd[\"state\"].astype(str)+m_census_pd[\"county\"]+m_census_pd[\"Census Tract\"]\n",
    "# m_census_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get census data for Boston\n",
    "b_census_data = c.acs5.get(('NAME','B01003_001E', 'B19013_001E', 'B17001_002E', 'B08301_001E', 'B08301_003E', 'B08101_041E',), geo={'for': 'tract:*',\n",
    "                       'in': 'state:{} county:025'.format(states.MA.fips)}) #  county:025 is Suffolk County\n",
    "\n",
    "# Convert to DataFrame\n",
    "b_census_pd = pd.DataFrame(b_census_data)\n",
    "\n",
    "# Column Reordering\n",
    "b_census_pd = b_census_pd.rename(columns={\"B01003_001E\": \"Population\",\n",
    "                                      \"B19013_001E\": \"Median Household Income\",\n",
    "                                      \"B17001_002E\": \"Poverty count\",\n",
    "                                      \"B08301_001E\": \"Commuting count\",\n",
    "                                      \"B08301_003E\": \"Commuting by car count\",\n",
    "                                      \"B08101_041E\": \"Commuting OTHER count\",\n",
    "                                      \"NAME\": \"Name\", \"tract\": \"Census Tract\"})\n",
    "\n",
    "# Add in Poverty Rate (Poverty Count / Population)\n",
    "b_census_pd[\"Poverty Rate\"] = 100 * \\\n",
    "    b_census_pd[\"Poverty count\"].astype(\n",
    "        int) / b_census_pd[\"Population\"].astype(int)\n",
    "\n",
    "# Calculate commute by car)\n",
    "b_census_pd[\"Car Rate\"] = 100 * \\\n",
    "    b_census_pd[\"Commuting by car count\"].astype(\n",
    "        int) / b_census_pd[\"Commuting count\"].astype(int)\n",
    "\n",
    "# Calculate commute by OTHER\n",
    "b_census_pd[\"Commute OTHER rate\"] = 100 * \\\n",
    "    b_census_pd[\"Commuting OTHER count\"].astype(\n",
    "        int) / b_census_pd[\"Commuting count\"].astype(int)\n",
    "\n",
    "# Calculate GEOID <= this is used to join to census geography\n",
    "b_census_pd[\"GEOID\"] = b_census_pd[\"state\"].astype(str)+b_census_pd[\"county\"]+b_census_pd[\"Census Tract\"]\n",
    "# b_census_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get census data for Portland\n",
    "# needed to pull several counties because Portland is in 3 different counties\n",
    "p_census_data = c.acs5.get(('NAME','B01003_001E', 'B19013_001E', 'B17001_002E', 'B08301_001E', 'B08301_003E', 'B08101_041E',), geo={'for': 'tract:*',\n",
    "                       'in': 'state:{} county:051,067,005'.format(states.OR.fips)}) # counties 051,067,005 are Multnomah, Washington, Clackamas\n",
    "\n",
    "# Convert to DataFrame\n",
    "p_census_pd = pd.DataFrame(p_census_data)\n",
    "\n",
    "# Column Reordering\n",
    "p_census_pd = p_census_pd.rename(columns={\"B01003_001E\": \"Population\",\n",
    "                                      \"B19013_001E\": \"Median Household Income\",\n",
    "                                      \"B17001_002E\": \"Poverty count\",\n",
    "                                      \"B08301_001E\": \"Commuting count\",\n",
    "                                      \"B08301_003E\": \"Commuting by car count\",\n",
    "                                      \"B08101_041E\": \"Commuting OTHER count\",\n",
    "                                      \"NAME\": \"Name\", \"tract\": \"Census Tract\"})\n",
    "\n",
    "# Add in Poverty Rate (Poverty Count / Population)\n",
    "p_census_pd[\"Poverty Rate\"] = 100 * \\\n",
    "    p_census_pd[\"Poverty count\"].astype(\n",
    "        int) / p_census_pd[\"Population\"].astype(int)\n",
    "\n",
    "# Calculate commute by car)\n",
    "p_census_pd[\"Car Rate\"] = 100 * \\\n",
    "    p_census_pd[\"Commuting by car count\"].astype(\n",
    "        int) / p_census_pd[\"Commuting count\"].astype(int)\n",
    "\n",
    "# Calculate commute by OTHER\n",
    "p_census_pd[\"Commute OTHER rate\"] = 100 * \\\n",
    "    p_census_pd[\"Commuting OTHER count\"].astype(\n",
    "        int) / p_census_pd[\"Commuting count\"].astype(int)\n",
    "\n",
    "# Calculate GEOID <= this is used to join to census geography\n",
    "p_census_pd[\"GEOID\"] = p_census_pd[\"state\"].astype(str)+p_census_pd[\"county\"]+p_census_pd[\"Census Tract\"]\n",
    "# p_census_pd.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # find the lowest median household income tracts and highest poverty tracts\n",
    "\n",
    "# <<<<<<< Minneapolis >>>>>>>\n",
    "# Sort by median household income, export low 25 to new df, create new column indicating if it is a low 25 census tract\n",
    "m_census_pd = m_census_pd.sort_values(\"Median Household Income\", ascending=True)\n",
    "m_mhi_25 = m_census_pd.head(25)\n",
    "m_census_pd[\"MHI_25\"] = np.where(m_census_pd['Median Household Income']<=m_mhi_25[\"Median Household Income\"].max(), 'yes', 'no')\n",
    "\n",
    "# Sort by poverty rate, export top 25 to new df, create new column indicating if it is a top 25 tract for poverty rate\n",
    "m_census_pd = m_census_pd.sort_values(\"Poverty Rate\", ascending=False)\n",
    "m_pvt_25 = m_census_pd.head(25)\n",
    "m_census_pd[\"PVT_25\"] = np.where(m_census_pd['Poverty Rate']>=m_pvt_25[\"Poverty Rate\"].min(), 'yes', 'no')\n",
    "\n",
    "# <<<<<<< Boston >>>>>>>\n",
    "# Sort by median household income, export low 25 to new df, create new column indicating if it is a low 25 census tract\n",
    "b_census_pd = b_census_pd.sort_values(\"Median Household Income\", ascending=True)\n",
    "b_mhi_25 = b_census_pd.head(25)\n",
    "b_census_pd[\"MHI_25\"] = np.where(b_census_pd['Median Household Income']<=b_mhi_25[\"Median Household Income\"].max(), 'yes', 'no')\n",
    "\n",
    "# Sort by poverty rate, export top 25 to new df, create new column indicating if it is a top 25 tract for poverty rate\n",
    "b_census_pd = b_census_pd.sort_values(\"Poverty Rate\", ascending=False)\n",
    "b_pvt_25 = b_census_pd.head(25)\n",
    "b_census_pd[\"PVT_25\"] = np.where(b_census_pd['Poverty Rate']>=b_pvt_25[\"Poverty Rate\"].min(), 'yes', 'no')\n",
    "\n",
    "# <<<<<<< Portland >>>>>>>\n",
    "# Portland -  Sort by median household income, export low 25 to new df, create new column indicating if it is a low 25 census tract\n",
    "p_census_pd = p_census_pd.sort_values(\"Median Household Income\", ascending=True)\n",
    "p_mhi_25 = p_census_pd.head(25)\n",
    "p_census_pd[\"MHI_25\"] = np.where(p_census_pd['Median Household Income']<=b_mhi_25[\"Median Household Income\"].max(), 'yes', 'no')\n",
    "\n",
    "# Sort by poverty rate, export top 25 to new df, create new column indicating if it is a top 25 tract for poverty rate\n",
    "p_census_pd = p_census_pd.sort_values(\"Poverty Rate\", ascending=False)\n",
    "p_pvt_25 = p_census_pd.head(25)\n",
    "p_census_pd[\"PVT_25\"] = np.where(p_census_pd['Poverty Rate']>=b_pvt_25[\"Poverty Rate\"].min(), 'yes', 'no')\n",
    "\n",
    "# export the new data frames to csv, to be read in by our geopandas python file\n",
    "m_census_pd.to_csv('census_output/m_census_25.csv')\n",
    "b_census_pd.to_csv('census_output/b_census_25.csv')\n",
    "p_census_pd.to_csv('census_output/p_census_25.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ===========================================\n",
    "# # need to go and run geo_merge_census.py \n",
    "# # this will read in our x_census_25 tables, and join them to a census shapefile for each city\n",
    "# # then it will join bike ride data to census tracts based on start locations\n",
    "# # ==========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read in csv of spatially joined census and bike data (these are HUGE)\n",
    "m_census_bike = pd.read_csv('output/m_sjoin.csv', index_col=0)\n",
    "b_census_bike = pd.read_csv('output/b_sjoin.csv', index_col=0)\n",
    "p_census_bike = pd.read_csv('output/p_sjoin.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create pie charts to show how many rides are occuring in lowest 25% or median household income\n",
    "\n",
    "# Extract a subset of the data frames containing only the fields that we care about\n",
    "m_census_bike_sub = m_census_bike[[\"GEOID\", \"Population\", \"Median Household Income\", \"Poverty Rate\", \"MHI_25\", \"PVT_25\", \"start station name\"]]\n",
    "b_census_bike_sub = b_census_bike[[\"GEOID\", \"Population\", \"Median Household Income\", \"Poverty Rate\", \"MHI_25\", \"PVT_25\", \"start station name\"]]\n",
    "# need to remove rows with missing data\n",
    "b_census_bike_sub = b_census_bike_sub[b_census_bike_sub[\"Median Household Income\"] != -666666666]\n",
    "p_census_bike_sub = p_census_bike[[\"GEOID\", \"Population\", \"Median Household Income\", \"Poverty Rate\", \"MHI_25\", \"PVT_25\", \"StartHub\"]]\n",
    "p_census_bike_sub = p_census_bike_sub[p_census_bike_sub[\"Median Household Income\"] != -666666666]\n",
    "\n",
    "# Create a function to create pie charts for MHI\n",
    "def piechart_mhi(df_subset, city):\n",
    "    # Find out how trips are in each group\n",
    "    mhi_groups = df_subset.groupby('MHI_25')\n",
    "    # # Chart our data, give it a title\n",
    "    explode = (.1, 0)\n",
    "    mhi_chart = mhi_groups['MHI_25'].count().plot(kind=\"pie\", title=(f\"{city} bike trips in lowest 25% of Median Household Income\"),\n",
    "                                               autopct=\"%1.1f%%\", explode = explode, startangle=140, shadow=True,)\n",
    "    mhi_chart.set_xlabel(\"\")\n",
    "    mhi_chart.set_ylabel(\"\")\n",
    "    plt.savefig(f'Images/{city}_MHI.png')\n",
    "    plt.show()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "# Create a function to create pie charts for Poverty Rate\n",
    "def piechart_pvt(df_subset, city):\n",
    "    # Find out how trips are in each group\n",
    "    pvt_groups = df_subset.groupby('PVT_25')\n",
    "    # # Chart our data, give it a title\n",
    "    explode = (.1, 0)\n",
    "    pvt_chart = pvt_groups['PVT_25'].count().plot(kind=\"pie\", title=(f\"{city} bike trips in highest 25% of Poverty Rate\"),\n",
    "                                               autopct=\"%1.1f%%\", colors = ['red', 'purple'], explode = explode, startangle=140, shadow=True,)\n",
    "    pvt_chart.set_xlabel(\"\")\n",
    "    pvt_chart.set_ylabel(\"\")\n",
    "    plt.savefig(f'Images/{city}_PVT.png')\n",
    "    plt.show()\n",
    "    plt.tight_layout()\n",
    "\n",
    "# run functions\n",
    "piechart_mhi(m_census_bike_sub, \"Minneapolis\")\n",
    "piechart_mhi(b_census_bike_sub, \"Boston\")\n",
    "piechart_mhi(p_census_bike_sub, \"Portland\")\n",
    "piechart_pvt(m_census_bike_sub, \"Minneapolis\")\n",
    "piechart_pvt(b_census_bike_sub, \"Boston\")\n",
    "piechart_pvt(p_census_bike_sub, \"Portland\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# # Run correlation between bike rides and median household income\n",
    "\n",
    "# Create a function to create pie charts for MHI\n",
    "def linregress(df_subset, city):\n",
    "    # Find out how many trips are in each census tract\n",
    "    geoid_grouped = df_subset.groupby(['GEOID'])\n",
    "    tract_mhi = geoid_grouped['Median Household Income'].mean()\n",
    "    tract_trips = geoid_grouped['Median Household Income'].count()\n",
    "    # perform linear regression and calculate regress values\n",
    "    (slope, intercept, rvalue, pvalue, stderr) = st.linregress(tract_mhi, tract_trips)\n",
    "    regress_values = tract_mhi * slope + intercept\n",
    "    # Create the line equation\n",
    "    line_eq = \"y = \" + str(round(slope,2)) + \"x + \" + str(round(intercept,2))\n",
    "    # plot the x and y columns, annotate the line equation\n",
    "    plt.plot(tract_mhi,regress_values,\"b-\")\n",
    "    plt.annotate(line_eq,(tract_mhi.min() + 5000,tract_trips.max() -5000),fontsize=15,color=\"blue\")\n",
    "    plt.scatter( tract_mhi, tract_trips, marker=\"o\", color=\"red\")\n",
    "    plt.title(f\"{city} census tract Median Household Income vs Number of Trips \")\n",
    "    plt.xlabel(\"Median Household Income\")\n",
    "    plt.ylabel(\"Number of Trips\")\n",
    "    print(f\"The r-squared is: {rvalue}\")\n",
    "    plt.savefig(f'Images/{city}_linregress.png')\n",
    "    plt.show()\n",
    "\n",
    "linregress(m_census_bike_sub, \"Minneapolis\")\n",
    "linregress(b_census_bike_sub, \"Boston\")\n",
    "linregress(p_census_bike_sub, \"Portland\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# # test null hypothesis on whehter high income areas ride bike shares more often or not\n",
    "# Extract individual groups\n",
    "m_geoid_grouped = m_census_bike_sub.groupby(['GEOID'])\n",
    "b_geoid_grouped = b_census_bike_sub.groupby(['GEOID'])\n",
    "p_geoid_grouped = p_census_bike_sub.groupby(['GEOID'])\n",
    "\n",
    "\n",
    "# Note: Setting equal_var=False performs Welch's t-test which does \n",
    "# not assume equal population variance\n",
    "def ttest(dataset1, dataset2, name1, name2):\n",
    "    test = st.ttest_ind(dataset1['GEOID'].count(), \n",
    "             dataset2['GEOID'].count(),\n",
    "             equal_var=False)\n",
    "    return print(f\"{name1} and {name2} number of trips dataset pvalue:{round(test[1], 5)}\" )\n",
    "ttest(m_geoid_grouped, b_geoid_grouped, \"Minneapolis\", \"Boston\" )\n",
    "ttest(m_geoid_grouped, p_geoid_grouped, \"Minneapolis\", \"Portland\" )\n",
    "ttest(b_geoid_grouped, p_geoid_grouped, \"Boston\", \"Portland\" )\n",
    "\n",
    "plt.subplot(1,1,1)\n",
    "plt.scatter(m_geoid_grouped['Median Household Income'].mean(), m_geoid_grouped['GEOID'].count(),label=f\"Minneapolis trips\", alpha=0.5)\n",
    "plt.scatter(b_geoid_grouped['Median Household Income'].mean(), b_geoid_grouped['GEOID'].count(), label=f\"Boston trips\", alpha=0.5)\n",
    "plt.scatter(p_geoid_grouped['Median Household Income'].mean(), p_geoid_grouped['GEOID'].count(), label=f\"Portland trips\", alpha=0.5)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(f\"City trips vs Median Household Income\")\n",
    "plt.xlabel(\"Median Household Income\")\n",
    "plt.ylabel(\"Number of trips\")\n",
    "plt.savefig(f'Images/Trips_vs_MHI_scatter.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================\n",
    "# End of Census vs bike (Carl's) code\n",
    "# ==================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paul's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msp = m_df[['start_time']]\n",
    "msp['Date'] = pd.to_datetime(msp['start_time']).dt.month.astype(int)\n",
    "msp['Time'] = pd.to_datetime(msp['start_time']).dt.hour.astype(int)\n",
    "msp_time = msp[['Date', 'Time']].dropna()\n",
    "bins = [-1, 2, 5, 8, 11, 14, 17, 20, 23]\n",
    "group_names = ['12am-3am', '3am-6am', '6am-9am', '9am-12pm', '12pm-3pm', '3pm-6pm', '6pm-9pm', '9pm-12am']\n",
    "msp_time['3-Hour Window'] = pd.cut(msp_time['Time'], bins, labels=group_names)\n",
    "msp_time['3-Hour Window'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_time_frame = [\"3a-6a\", \"6a-9a\", \"9a-12p\", \"12p-3p\", \"3p-6p\", \"6p-9p\", \"9p-12a\", \"12a-3a\"]\n",
    "m_total_rides = [3718, 37829, 59063, 83444, 105183, 78172, 33717, 11297]\n",
    "x_axis_1 = np.arange(len(m_total_rides))\n",
    "\n",
    "plt.bar(x_axis_1, m_total_rides, color=\"b\", align=\"center\")\n",
    "\n",
    "tick_locations = [value for value in x_axis_1]\n",
    "plt.xticks(tick_locations, m_time_frame)\n",
    "\n",
    "plt.xlim(-0.75, len(x_axis_1)-0.25)\n",
    "\n",
    "plt.ylim(0, max(m_total_rides)+5000)\n",
    "\n",
    "plt.title(\"2018 Minneapolis Bike Share\")\n",
    "plt.xlabel(\"Time of Day\")\n",
    "plt.ylabel(\"Total Rides\")\n",
    "\n",
    "plt.savefig(\"Images/MplsBike1.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msp_time['Date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_time_months = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "m_month_rides = [0, 0, 0, 18303, 66882, 74349, 86008, 71734, 56692, 33384, 5071, 0]\n",
    "x_axis_2 = np.arange(len(m_month_rides))\n",
    "\n",
    "plt.bar(x_axis_2, m_month_rides, color=\"r\", align=\"center\")\n",
    "\n",
    "tick_locations = [value for value in x_axis_2]\n",
    "plt.xticks(tick_locations, m_time_months)\n",
    "\n",
    "plt.xlim(-0.75, len(x_axis_2)-0.25)\n",
    "\n",
    "plt.ylim(0, max(m_month_rides)+5000)\n",
    "\n",
    "plt.title(\"2018 Minneapolis Bike Share\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Total Rides\")\n",
    "\n",
    "plt.savefig(\"Images/MplsBike2.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos = b_df[['starttime']]\n",
    "bos['Date'] = pd.to_datetime(bos['starttime']).dt.month.astype(int)\n",
    "bos['Time'] = pd.to_datetime(bos['starttime']).dt.hour.astype(int)\n",
    "bos_time = bos[['Date', 'Time']].dropna()\n",
    "bins = [-1, 2, 5, 8, 11, 14, 17, 20, 23]\n",
    "group_names = ['12am-3am', '3am-6am', '6am-9am', '9am-12pm', '12pm-3pm', '3pm-6pm', '6pm-9pm', '9pm-12am']\n",
    "bos_time['3-Hour Window'] = pd.cut(bos_time['Time'], bins, labels=group_names)\n",
    "bos_time['3-Hour Window'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_time_frame = [\"3a-6a\", \"6a-9a\", \"9a-12p\", \"12p-3p\", \"3p-6p\", \"6p-9p\", \"9p-12a\", \"12a-3a\"]\n",
    "b_total_rides = [15127, 299606, 250524, 276965, 459267, 320993, 115642, 29682]\n",
    "x_axis_3 = np.arange(len(b_total_rides))\n",
    "\n",
    "plt.bar(x_axis_3, b_total_rides, color=\"b\", align=\"center\")\n",
    "\n",
    "tick_locations = [value for value in x_axis_3]\n",
    "plt.xticks(tick_locations, b_time_frame)\n",
    "\n",
    "plt.xlim(-0.75, len(x_axis_3)-0.25)\n",
    "\n",
    "plt.ylim(0, max(b_total_rides)+5000)\n",
    "\n",
    "plt.title(\"2018 Boston Bike Share\")\n",
    "plt.xlabel(\"Time of Day\")\n",
    "plt.ylabel(\"Total Rides\")\n",
    "\n",
    "plt.savefig(\"Images/BostonBike1.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos_time['Date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_time_months = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "b_month_rides = [40932, 62817, 62895, 98194, 178865, 205359, 242916, 236076, 236182, 200100, 121419, 81961]\n",
    "x_axis_4 = np.arange(len(b_month_rides))\n",
    "\n",
    "plt.bar(x_axis_4, b_month_rides, color=\"r\", align=\"center\")\n",
    "\n",
    "tick_locations = [value for value in x_axis_4]\n",
    "plt.xticks(tick_locations, b_time_months)\n",
    "\n",
    "plt.xlim(-0.75, len(x_axis_4)-0.25)\n",
    "\n",
    "plt.ylim(0, max(b_month_rides)+5000)\n",
    "\n",
    "plt.title(\"2018 Boston Bike Share\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Total Rides\")\n",
    "\n",
    "plt.savefig(\"Images/BostonBike2.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "por_time = p_df[['StartDate', 'StartTime']]\n",
    "por_time['Date'] = pd.to_datetime(por_time['StartDate']).dt.month.astype(int)\n",
    "por_time['Time'] = pd.to_datetime(por_time['StartTime']).dt.hour.astype(int)\n",
    "por_time = por_time[['Date', 'Time']].dropna()\n",
    "bins = [-1, 2, 5, 8, 11, 14, 17, 20, 23]\n",
    "group_names = ['12am-3am', '3am-6am', '6am-9am', '9am-12pm', '12pm-3pm', '3pm-6pm', '6pm-9pm', '9pm-12am']\n",
    "por_time['3-Hour Window'] = pd.cut(por_time['Time'], bins, labels=group_names)\n",
    "por_time['3-Hour Window'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_time_frame = [\"3a-6a\", \"6a-9a\", \"9a-12p\", \"12p-3p\", \"3p-6p\", \"6p-9p\", \"9p-12a\", \"12a-3a\"]\n",
    "p_total_rides = [4672, 38132, 55706, 82920, 100191, 73097, 35652, 9585]\n",
    "x_axis_5 = np.arange(len(p_total_rides))\n",
    "\n",
    "plt.bar(x_axis_5, p_total_rides, color=\"b\", align=\"center\")\n",
    "\n",
    "tick_locations = [value for value in x_axis_5]\n",
    "plt.xticks(tick_locations, p_time_frame)\n",
    "\n",
    "plt.xlim(-0.75, len(x_axis_5)-0.25)\n",
    "\n",
    "plt.ylim(0, max(p_total_rides)+5000)\n",
    "\n",
    "plt.title(\"2018 Portland Bike Share\")\n",
    "plt.xlabel(\"Time of Day\")\n",
    "plt.ylabel(\"Total Rides\")\n",
    "\n",
    "plt.savefig(\"Images/PortlandBike1.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "por_time['Date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_time_months = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "p_month_rides = [12648, 13007, 22584, 22647, 79399, 48783, 56967, 46087, 35308, 27496, 20164, 14865]\n",
    "x_axis_6 = np.arange(len(p_month_rides))\n",
    "\n",
    "plt.bar(x_axis_6, p_month_rides, color=\"r\", align=\"center\")\n",
    "\n",
    "tick_locations = [value for value in x_axis_6]\n",
    "plt.xticks(tick_locations, p_time_months)\n",
    "\n",
    "plt.xlim(-0.75, len(x_axis_6)-0.25)\n",
    "\n",
    "plt.ylim(0, max(p_month_rides)+5000)\n",
    "\n",
    "plt.title(\"2018 Portland Bike Share\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Total Rides\")\n",
    "\n",
    "plt.savefig(\"Images/PortlandBike2.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MICAH'S CODE SECTION \n",
    "\n",
    "# =================================================================================================\n",
    "# IDENTIFYING AND CLEANING OUR INDIVIDUAL CITY BIKE SHARE DATAFRAMES FOR OUR DATES FROM CARL'S CODE\n",
    "# =================================================================================================\n",
    "\n",
    "# PORTLAND 'BIKETOWN' BIKE SHARE INFORMATION DATAFRAME FOR 2018 ----------------------------------\n",
    "# SELECTING DESIRED COLUMNS - MONTH : 'Month', DISTANCE : 'Distance_Miles', USER TYPE : 'PaymentPlan', \n",
    "# TRIP DURATION : 'Duration' AND START DATE : 'StartDate'\n",
    "p_df_desired = p_df[[\"Month\", \"Distance_Miles\", \"PaymentPlan\", \"Duration\", \"StartDate\"]]\n",
    "\n",
    "# CLEANING DATAFRAME COLUMN NAMES FOR PORTLAND BIKE SHARE INFORMATION\n",
    "p_df_clean_m = p_df_desired.rename(columns = {\"Distance_Miles\": \"Distance Traveled (mi)\",\n",
    "                                              \"PaymentPlan\": \"User Type\",\n",
    "                                              \"Duration\" : \"Trip Duration\",\n",
    "                                              \"StartDate\" : \"Trip Date\"})\n",
    "\n",
    "# MINNEAPOLIS 'NICERIDE' BIKE SHARE INFORMATION DATAFRAME FOR 2018 ------------------------------\n",
    "# SELECTING DESIRED COLUMNS - MONTH : 'Month', USER TYPE : 'usertype', GENDER : 'gender', TRIP DURATION : 'tripduration'\n",
    "# AND START DATE : 'start_time'\n",
    "m_df_desired = m_df[[\"Month\", \"usertype\", \"gender\", \"tripduration\", \"start_time\"]]\n",
    "\n",
    "# CLEANING DATAFRAME COLUMN NAMES FOR MINNEAPOLIS BIKE SHARE INFORMATION\n",
    "m_df_clean_m = m_df_desired.rename(columns = {\"usertype\": \"User Type\",\n",
    "                                              \"gender\": \"User Gender\",\n",
    "                                              \"tripduration\" : \"Trip Duration\",\n",
    "                                              \"start_time\" : \"Trip Date\"})\n",
    "\n",
    "# BOSTON 'BLUEBIKES' BIKE SHARE INFORMATION DATAFRAME FOR 2018 ----------------------------------\n",
    "# SELECTING DESIRED COLUMNS - MONTH : 'Month', USER TYPE : 'usertype', GENDER : 'gender', TRIP DURATION : 'tripduration'\n",
    "# AND START DATE : 'starttime'\n",
    "b_df_desired = b_df[[\"Month\", \"usertype\", \"gender\", \"tripduration\", \"starttime\"]]\n",
    "\n",
    "# CLEANING DATAFRAME COLUMN NAMES FOR BOSTON BIKE SHARE INFORMATION\n",
    "b_df_clean_m = b_df_desired.rename(columns = {\"usertype\": \"User Type\",\n",
    "                                              \"gender\": \"User Gender\",\n",
    "                                              \"tripduration\" : \"Trip Duration\",\n",
    "                                              \"starttime\" : \"Trip Date\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_df_clean_m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_df_clean_m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_df_clean_m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================================\n",
    "# GETTING HISTORICAL WEATHER DATA FROM 01 JANUARY 2018 THROUGH 31 DECEMBER 2018 (OBTAINED THROUGH NOAA)\n",
    "# =================================================================================================\n",
    "\n",
    "# READING IN .CSV FILE CALLED 'Weather-Data.csv'\n",
    "weather_data_df = pd.read_csv(\"resources/Weather-Data.csv\")\n",
    "\n",
    "weather_data_df\n",
    "\n",
    "# CLEANING DATAFRAME COLUMN NAMES\n",
    "weather_data_df = weather_data_df.rename( columns = {'AWND' : 'Average Wind Speed',\n",
    "                                                     'NAME' : 'Name',\n",
    "                                                     'DATE' : 'Date',\n",
    "                                                     'MDPR' : 'Multiday Precipitation Total',\n",
    "                                                     'PGTM' : 'Peak Gust Time',\n",
    "                                                     'PRCP' : 'Precipitation',\n",
    "                                                     'PSUN' : 'Daily Percent of Possible Sunshine',\n",
    "                                                     'SNOW' : 'Snowfall',\n",
    "                                                     'SNWD' : 'Snow Depth',\n",
    "                                                     'TAVG' : 'Average Temperature',\n",
    "                                                     'TMAX' : 'Maximum Temperature',\n",
    "                                                     'TMIN' : 'Minimum Temperature',\n",
    "                                                     'TOBS' : 'Temperature at Time of Observation',\n",
    "                                                     'TSUN' : 'Total Sunshine',\n",
    "                                                     'WDMV' : 'Total Wind Movement',\n",
    "                                                     'WT01' : 'Fog, Ice Fog, or Freezing Fog',\n",
    "                                                     'WT02' : 'Heavy Fog or Heaving Freezing Fog',\n",
    "                                                     'WT03' : 'Thunder',\n",
    "                                                     'WT04' : 'Ice pellets, Sleet, Snow Pellets, or Small Hail',\n",
    "                                                     'WT05' : 'Hail',\n",
    "                                                     'WT08' : 'Smoke or Haze',\n",
    "                                                     'WT09' : 'Blowing or Drifting Snow',\n",
    "                                                     'WT11' : 'High or Damaging Winds'})\n",
    "\n",
    "# FILLING NAN VALUES WITH ZEROS\n",
    "weather_data_df_cleaned = weather_data_df.fillna(0)\n",
    "\n",
    "# SELECTING ONLY COLUMNS WE WANT AND HAVE CLEANED\n",
    "weather_data_df_cleansed = weather_data_df_cleaned[[\"Name\",\n",
    "                                                    \"Date\",\n",
    "                                                    \"Average Wind Speed\",\n",
    "                                                    \"Multiday Precipitation Total\",\n",
    "                                                    \"Peak Gust Time\",\n",
    "                                                    \"Precipitation\",\n",
    "                                                    \"Daily Percent of Possible Sunshine\",\n",
    "                                                    \"Snowfall\",\n",
    "                                                    \"Snow Depth\",\n",
    "                                                    \"Average Temperature\",\n",
    "                                                    \"Maximum Temperature\",\n",
    "                                                    \"Minimum Temperature\",\n",
    "                                                    \"Temperature at Time of Observation\",\n",
    "                                                    \"Total Sunshine\",\n",
    "                                                    \"Total Wind Movement\",\n",
    "                                                    \"Fog, Ice Fog, or Freezing Fog\",\n",
    "                                                    \"Heavy Fog or Heaving Freezing Fog\",\n",
    "                                                    \"Thunder\",\n",
    "                                                    \"Ice pellets, Sleet, Snow Pellets, or Small Hail\",\n",
    "                                                    \"Hail\",\n",
    "                                                    \"Smoke or Haze\",\n",
    "                                                    \"Blowing or Drifting Snow\",\n",
    "                                                    \"High or Damaging Winds\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALIZING A LIST OF OUR CITIES\n",
    "cities_m = ['boston', 'minneapolis', 'portland']\n",
    "\n",
    "# SPLITTING 'Name' COLUMN TO FIRST WORD ONLY AND PLACING IN NEW COLUMN CALLED 'city_name'\n",
    "weather_data_df_cleansed[\"city_name\"] = weather_data_df_cleansed[\"Name\"].str.split(\" \").str[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISOLATING OUR CITIES WEATHER\n",
    "boston_weather = weather_data_df_cleansed.loc[weather_data_df_cleansed['city_name'] == cities_m[0].upper() , :]\n",
    "minneapolis_weather = weather_data_df_cleansed.loc[weather_data_df_cleansed['city_name'] == cities_m[1].upper() , :]\n",
    "portland_weather = weather_data_df_cleansed.loc[weather_data_df_cleansed['city_name'] == cities_m[2].upper() , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANAGING BOSTON =================================================================================\n",
    "# MERGING BIKE SHARE AND WEATHER DATE FOR BOSTON ON DATE\n",
    "boston_merged = pd.DataFrame.merge(boston_weather, b_df_clean_m, on = 'Date', how = 'outer')\n",
    "\n",
    "# CONVERTING ALL DATES TO SAME FORMAT, PLACING IN NEW COLUMN CALLED 'Datetime'\n",
    "boston_merged[\"Datetime\"] = pd.to_datetime(boston_merged[\"Date\"]).astype(str)\n",
    "\n",
    "# \n",
    "# SEPERATING JUST THE DATE, REMOVING THE TIME FROM 'Datetime' COLUMN\n",
    "boston_merged[\"Day\"] = boston_merged[\"Datetime\"].str.split(\" \").str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANAGING MINNEAPOLIS =================================================================================\n",
    "# MERGING BIKE SHARE AND WEATHER DATE FOR BOSTON ON DATE\n",
    "minneapolis_merged = pd.DataFrame.merge(minneapolis_weather, m_df_clean_m, on = 'Date', how = 'outer')\n",
    "\n",
    "# CONVERTING ALL DATES TO SAME FORMAT, PLACING IN NEW COLUMN CALLED 'Datetime'\n",
    "minneapolis_merged[\"Datetime\"] = pd.to_datetime(minneapolis_merged[\"Date\"]).astype(str)\n",
    "\n",
    "# \n",
    "# SEPERATING JUST THE DATE, REMOVING THE TIME FROM 'Datetime' COLUMN\n",
    "minneapolis_merged[\"Day\"] = minneapolis_merged[\"Datetime\"].str.split(\" \").str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANAGING PORTLAND =================================================================================\n",
    "# MERGING BIKE SHARE AND WEATHER DATE FOR BOSTON ON DATE\n",
    "portland_merged = pd.DataFrame.merge(portland_weather, p_df_clean_m, on = 'Date', how = 'outer')\n",
    "\n",
    "# CONVERTING ALL DATES TO SAME FORMAT, PLACING IN NEW COLUMN CALLED 'Datetime'\n",
    "portland_merged[\"Datetime\"] = pd.to_datetime(portland_merged[\"Date\"]).astype(str)\n",
    "\n",
    "# SEPERATING JUST THE DATE, REMOVING THE TIME FROM 'Datetime' COLUMN\n",
    "portland_merged[\"Day\"] = portland_merged[\"Datetime\"].str.split(\" \").str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting some portland data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# DEFINING LIST OF USER TYPES\n",
    "user_types_p = [\"Subscriber\" , \"Casual\"]\n",
    "\n",
    "# AVERAGE DISTRANCE TRAVELED FOR EACH GROUP OF USER CLASSIFICATIONS IN PORTALND FOR ENTIRE YEAR\n",
    "average_annual_distance_by_user_type_p = portland_merged.groupby([\"User Type\"])[\"Distance Traveled (mi)\"].mean()\n",
    "\n",
    "# TOTAL DISTANCE TRAVLED BY USER TYPES OVER THE YEAR IN PORTLAND\n",
    "total_distance_by_user_type_p = portland_merged.groupby([\"User Type\"])[\"Distance Traveled (mi)\"].sum()\n",
    "\n",
    "# COUNT OF HOW MANY RIDES WERE TAKEN FOR USER TYPES THERE ARE IN PORTLAND\n",
    "rides_per_user_type_p = portland_merged[\"User Type\"].value_counts()\n",
    "\n",
    "# PLOTTING RIDE COUNT PER USER TYPE IN PORTLAND\n",
    "plt.bar(user_types_p, rides_per_user_type_p, color = 'black')\n",
    "plt.title('Number of Rides Taken in Portland, OR per User Type in 2018')\n",
    "plt.xlabel('User Type')\n",
    "plt.ylabel('Number of Rides')\n",
    "plt.savefig(\"Images/number_rides_user_portland.png\")\n",
    "plt.show()\n",
    "\n",
    "# switching list order for next bar graphs\n",
    "user_type_casual_first = [\"Casual\", \"Subscriber\"]\n",
    "\n",
    "# plotting subscriber type vs mean distance traveled per trip\n",
    "plt.bar(user_type_casual_first, average_annual_distance_by_user_type_p, color = 'black')\n",
    "plt.title('Average Trip Distance Traveled per Subscriber Type in Portland, OR during 2018')\n",
    "plt.xlabel('Subscriber Type')\n",
    "plt.ylabel('Distance Traveled (mi)')\n",
    "plt.savefig(\"Images/mean_distance_per_user_portland.png\")\n",
    "plt.show()\n",
    "\n",
    "# # plotting subscriber type vs total distance traveled \n",
    "plt.bar(user_type_casual_first, total_distance_by_user_type_p, color = 'black')\n",
    "plt.title('Total Distance Traveled per Subscriber Type in Portland, OR during 2018')\n",
    "plt.xlabel('Subscriber Type')\n",
    "plt.ylabel('Distance Traveled (mi)')\n",
    "plt.savefig(\"Images/total_distance_per_user_portland.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOOKING AT MINNEAPOLIS USER TYPE DATA\n",
    "\n",
    "# GET DISTANCE BETWEEN LATITUDE AND LONGITUDE POINTS FOR MINNEAPOLIS RIDES\n",
    "from geopy import distance\n",
    "\n",
    "m_start_lat = list(m_df[\"start station latitude\"])\n",
    "m_start_lng = list(m_df[\"start station longitude\"])\n",
    "m_end_lat = list(m_df[\"end station latitude\"])\n",
    "m_end_lng = list(m_df[\"end station longitude\"])\n",
    "\n",
    "i = 0 \n",
    "\n",
    "minneapolis_trip_distances = []\n",
    "\n",
    "for i in np.arange(len(m_start_lat)):\n",
    "    \n",
    "    minneapolis_trip_distances.append(distance.distance((m_start_lat[i], m_start_lng[i]), (m_end_lat[i], m_end_lng[i])).miles)\n",
    "   \n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD TRIP DISTANCES COLUMN TO THE MINNEAPOLIS BIKE SHARE DATAFRAME\n",
    "m_df_clean_m[\"Distance Traveled (mi)\"] = minneapolis_trip_distances\n",
    "\n",
    "# AVERAGE DISTRANCE TRAVELED FOR EACH GROUP OF USER CLASSIFICATIONS IN MINEAPOLIS FOR ENTIRE 2018\n",
    "average_annual_distance_by_user_type_m = m_df_clean_m.groupby([\"User Type\"])[\"Distance Traveled (mi)\"].mean()\n",
    "\n",
    "# TOTAL DISTANCE TRAVLED BY USER TYPES OVER THE YEAR IN PORTLAND\n",
    "total_distance_by_user_type_m = m_df_clean_m.groupby([\"User Type\"])[\"Distance Traveled (mi)\"].sum()\n",
    "\n",
    "# COUNT OF HOW MANY RIDES WERE TAKEN FOR USER TYPES THERE ARE IN PORTLAND\n",
    "rides_per_user_type_m = m_df_clean_m[\"User Type\"].value_counts()\n",
    "\n",
    "user_type_list_m = list(m_df_clean_m[\"User Type\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTING MINNEAPOLIS USER TYPE COMPARISONS\n",
    "# PLOTTING RIDE COUNT PER USER TYPE IN MINNEAPOLIS\n",
    "plt.bar(user_type_list_m, rides_per_user_type_m, color = 'black')\n",
    "plt.title('Number of Rides Taken in Minneapolis, MN by User Type in 2018')\n",
    "plt.xlabel('User Type')\n",
    "plt.ylabel('Number of Rides')\n",
    "plt.savefig(\"Images/number_rides_user_minneapolis.png\")\n",
    "plt.show()\n",
    "\n",
    "# plotting subscriber type vs mean distance traveled per trip\n",
    "plt.bar(user_type_list_m, average_annual_distance_by_user_type_m, color = 'black')\n",
    "plt.title('Average Trip Distance Traveled by User Type in Minneapolis, MN during 2018')\n",
    "plt.xlabel('User Type')\n",
    "plt.ylabel('Distance Traveled (mi)')\n",
    "plt.savefig(\"Images/mean_distance_per_user_minneapolis.png\")\n",
    "plt.show()\n",
    "\n",
    "# # plotting subscriber type vs total distance traveled \n",
    "plt.bar(user_type_list_m, total_distance_by_user_type_m, color = 'black')\n",
    "plt.title('Total Distance Traveled by User Type in Minneapolis, MN during 2018')\n",
    "plt.xlabel('User Type')\n",
    "plt.ylabel('Distance Traveled (mi)')\n",
    "plt.savefig(\"Images/total_distance_per_user_minneapolis.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET DISTANCE BETWEEN START AND END GEO-COORDINATES FOR BOSTON RIDES\n",
    "\n",
    "b_start_lat = list(b_df[\"start station latitude\"])\n",
    "b_start_lng = list(b_df[\"start station longitude\"])\n",
    "b_end_lat = list(b_df[\"end station latitude\"])\n",
    "b_end_lng = list(b_df[\"end station longitude\"])\n",
    "\n",
    "i = 0 \n",
    "\n",
    "boston_trip_distances = []\n",
    "\n",
    "for i in np.arange(len(b_start_lat)):\n",
    "    \n",
    "    boston_trip_distances.append(distance.distance((b_start_lat[i], b_start_lng[i]), (b_end_lat[i], b_end_lng[i])).miles)\n",
    "   \n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD TRIP DISTANCES COLUMN TO THE MINNEAPOLIS BIKE SHARE DATAFRAME\n",
    "b_df_clean_m[\"Distance Traveled (mi)\"] = boston_trip_distances\n",
    "\n",
    "# AVERAGE DISTRANCE TRAVELED FOR EACH GROUP OF USER CLASSIFICATIONS IN MINEAPOLIS FOR ENTIRE 2018\n",
    "average_annual_distance_by_user_type_b = b_df_clean_m.groupby([\"User Type\"])[\"Distance Traveled (mi)\"].mean()\n",
    "\n",
    "# TOTAL DISTANCE TRAVLED BY USER TYPES OVER THE YEAR IN PORTLAND\n",
    "total_distance_by_user_type_b = b_df_clean_m.groupby([\"User Type\"])[\"Distance Traveled (mi)\"].sum()\n",
    "\n",
    "# COUNT OF HOW MANY RIDES WERE TAKEN FOR USER TYPES THERE ARE IN PORTLAND\n",
    "rides_per_user_type_b = b_df_clean_m[\"User Type\"].value_counts()\n",
    "\n",
    "user_type_list_b = list(b_df_clean_m[\"User Type\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTING USER TYPE TRIP RELATIONSHIPS FOR BOSTON RIDES IN 2018 \n",
    "# PLOTTING RIDE COUNT PER USER TYPE IN BOSTON\n",
    "plt.bar(user_type_list_b, rides_per_user_type_b, color = 'black')\n",
    "plt.title('Number of Rides Taken in Boston, MA by User Type in 2018')\n",
    "plt.xlabel('User Type')\n",
    "plt.ylabel('Number of Rides')\n",
    "plt.savefig(\"Images/number_rides_user_boston.png\")\n",
    "plt.show()\n",
    "\n",
    "# plotting subscriber type vs mean distance traveled per trip\n",
    "plt.bar(user_type_list_b, average_annual_distance_by_user_type_b, color = 'black')\n",
    "plt.title('Average Trip Distance Traveled by User Type in Boston, MA during 2018')\n",
    "plt.xlabel('User Type')\n",
    "plt.ylabel('Distance Traveled (mi)')\n",
    "plt.savefig(\"Images/mean_distance_per_user_boston.png\")\n",
    "plt.show()\n",
    "\n",
    "# # plotting subscriber type vs total distance traveled \n",
    "plt.bar(user_type_list_m, total_distance_by_user_type_m, color = 'black')\n",
    "plt.title('Total Distance Traveled by User Type in Boston, MA during 2018')\n",
    "plt.xlabel('User Type')\n",
    "plt.ylabel('Distance Traveled (mi)')\n",
    "plt.savefig(\"Images/total_distance_per_user_boston.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARING RIDES BY MONTH ===============================================\n",
    "\n",
    "# DEFINING ACTIVE MONTHS LIST FOR EACH CITY\n",
    "active_months_mpls = list(m_df_clean_m[\"Month\"].unique())\n",
    "active_months_boston = list(b_df_clean_m[\"Month\"].unique())\n",
    "active_months_portland = list(p_df_clean_m[\"Month\"].unique())\n",
    "\n",
    "# DEFINING RIDES PER MONTH\n",
    "monthly_rides_m = m_df_clean_m.groupby(\"Month\", sort = False)[\"User Type\"].count()\n",
    "monthly_rides_b = b_df_clean_m.groupby(\"Month\", sort = False)[\"User Type\"].count()\n",
    "monthly_rides_p = p_df_clean_m.groupby(\"Month\", sort = False)[\"User Type\"].count()\n",
    "\n",
    "# PLOTTING RIDES PER MONTH FOR EACH CITY\n",
    "# MINNEAPOLIS RIDES PER MONTH BAR GRAPH\n",
    "plt.bar(active_months_mpls, monthly_rides_m, color = 'black')\n",
    "plt.title('Number of Rides Taken per Month in Minneapolis, MN in 2018')\n",
    "plt.xticks(rotation = 45)\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of Rides')\n",
    "plt.savefig(\"Images/number_rides_per_month_mpls.png\")\n",
    "plt.show()\n",
    "\n",
    "# BOSTON RIDES PER MONTH BAR GRAPH\n",
    "plt.bar(active_months_boston, monthly_rides_b, color = 'black')\n",
    "plt.title('Number of Rides Taken per Month in Boston, MA in 2018')\n",
    "plt.xticks(rotation = 45)\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of Rides')\n",
    "plt.savefig(\"Images/number_rides_per_month_boston.png\")\n",
    "plt.show()\n",
    "\n",
    "# PORTLAND RIDES PER MONTH BAR GRAPH\n",
    "plt.bar(active_months_portland, monthly_rides_p, color = 'black')\n",
    "plt.title('Number of Rides Taken per Month in Portland, OR in 2018')\n",
    "plt.xticks(rotation = 45)\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of Rides')\n",
    "plt.savefig(\"Images/number_rides_per_month_portland.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING EACH RIDES BY MONTH SET FOR NORMAL DISTRIBUTION USING scipy.stats.normaltest() ======================================\n",
    "# If p value is >= .5 , data is normal (support null hypothesis)\n",
    "import scipy.stats as sts\n",
    "\n",
    "# minneapolis normal test\n",
    "m_normal_test = sts.normaltest(monthly_rides_m)\n",
    "\n",
    "# boston normal test\n",
    "b_normal_test = sts.normaltest(monthly_rides_b)\n",
    "\n",
    "# portland normal test\n",
    "p_normal_test = sts.normaltest(monthly_rides_p)\n",
    "\n",
    "# print statement sumamrizing normal tests for rides per month across the three cities\n",
    "print(f\"\"\"The p-value for Minneapolis' rides per month data is: {m_normal_test[1]}.\n",
    "The p-value for Boston's rides per month data is: {b_normal_test[1]}.\n",
    "The p-value for Portland's rides per month data is: {p_normal_test[1]}\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for ridership in rain\n",
    "portland_rain = portland_merged.loc[(portland_merged[\"Precipitation\"] > 0) & ((portland_merged['User Type'] == 'Subscriber') | (portland_merged['User Type'] == 'Casual')), :]\n",
    "minneapolis_rain = minneapolis_merged.loc[(minneapolis_merged[\"Precipitation\"] > 0) & ((minneapolis_merged['User Type'] == 'Subscriber') | (minneapolis_merged['User Type'] == 'Customer')), :]\n",
    "boston_rain = boston_merged.loc[(boston_merged[\"Precipitation\"] > 0) & ((boston_merged['User Type'] == 'Subscriber') | (boston_merged['User Type'] == 'Customer')), :]\n",
    "\n",
    "print(f\"Number of riders who rode in the rain in Portland: {len(portland_rain)}, in Minneapolis: {len(minneapolis_rain)}, and in Boston: {len(boston_rain)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for ridership in high winds\n",
    "portland_wind = portland_merged.loc[(portland_merged[\"High or Damaging Winds\"] > 0) & ((portland_merged['User Type'] == 'Subscriber') | (portland_merged['User Type'] == 'Casual')), :]\n",
    "minneapolis_wind = minneapolis_merged.loc[(minneapolis_merged[\"High or Damaging Winds\"] > 0) & ((minneapolis_merged['User Type'] == 'Subscriber') | (minneapolis_merged['User Type'] == 'Customer')), :]\n",
    "boston_wind = boston_merged.loc[(boston_merged[\"High or Damaging Winds\"] > 0) & ((boston_merged['User Type'] == 'Subscriber') | (boston_merged['User Type'] == 'Customer')), :]\n",
    "\n",
    "print(f\"Number of riders who rode through high winds in Portland: {len(portland_wind)}, in Minneapolis: {len(minneapolis_wind)}, and in Boston: {len(boston_wind)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portland_merged.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minneapolis_merged.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_merged.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
